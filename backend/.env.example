# The Llama Cloud API key.
LLAMA_CLOUD_API_KEY=your_llama_cloud_api_key_here

# The provider for the AI models to use.
# Options: cerebras, openai, nvidia, groq, ollama, anthropic, gemini, mistral, azure-openai
MODEL_PROVIDER=cerebras

# The name of LLM model to use.
# For Cerebras: llama-4-maverick-17b-128e-instruct (recommended), llama3.1-8b, llama3.1-70b
# For OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
MODEL=llama-4-maverick-17b-128e-instruct

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# Dimension of the embedding model to use.
EMBEDDING_DIM=1536

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The OpenAI API key to use.
OPENAI_API_KEY=your_openai_api_key_here

# The AIML API key to use.
AIML_API_KEY=your_aiml_api_key_here

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
# TOP_K=

# The name of the LlamaCloud index to use (part of the LlamaCloud project).
LLAMA_CLOUD_INDEX_NAME=test

# The name of the LlamaCloud project.
LLAMA_CLOUD_PROJECT_NAME=Default

# The base URL for the LlamaCloud API. Only change this for non-production environments
LLAMA_CLOUD_BASE_URL=https://api.cloud.llamaindex.ai

# The organization ID for the LlamaCloud project (uses default organization if not specified)
# LLAMA_CLOUD_ORGANIZATION_ID=

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:8000/api/files

# The address to start the backend app.
APP_HOST=0.0.0.0

# The port to start the backend app.
APP_PORT=8000

# E2B_API_KEY key is required to run code interpreter tool.
E2B_API_KEY=your_e2b_api_key_here

# Customize prompt to generate the next question suggestions based on the conversation history.
NEXT_QUESTION_PROMPT="You're a helpful assistant! Your task is to suggest the next question that user might ask. 
Here is the conversation history
---------------------
{conversation}
---------------------
Given the conversation history, please give me 3 questions that you might ask next!
Your answer should be wrapped in three sticks which follows the following format:
```
<question 1>
<question 2>
<question 3>
```"

TAVILY_API_KEY=your_tavily_api_key_here

FIRECRAWL_API_KEY=your_firecrawl_api_key_here

SENDGRID_API_KEY=your_sendgrid_api_key_here

SENDER_EMAIL=your_sender_email_here

ELEVENLABS_API_KEY=your_elevenlabs_api_key_here

NVIDIA_NIM_API_KEY=your_nvidia_nim_api_key_here

SERP_API_KEY=your_serp_api_key_here

# Cerebras API key (REQUIRED for Cerebras provider)
CEREBRAS_API_KEY=your_cerebras_api_key_here

# Docker MCP Configuration (Optional but recommended for enhanced features)
MCP_GATEWAY_URL=http://localhost:8080
BRAVE_API_KEY=your_brave_api_key_here
REDDIT_CLIENT_ID=your_reddit_client_id_here
REDDIT_CLIENT_SECRET=your_reddit_client_secret_here
GITHUB_TOKEN=your_github_token_here
NOTION_TOKEN=your_notion_token_here
NOTION_DATABASE_ID=your_notion_database_id_here
MONGO_URI=mongodb://localhost:27017/startupscout